{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115634dd8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    normal_array = x/255\n",
    "    \n",
    "    return normal_array\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "labels_range = pd.get_dummies([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded \n",
    "    vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function    \n",
    "    \n",
    "    one_hot = np.zeros((len(x),10))\n",
    "    for i in range(len(x)):\n",
    "        one_hot[i] = labels_range[x[i]]\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    height = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    \n",
    "    return tf.placeholder(tf.float32, \n",
    "                          [None, height, width, image_shape[2]], \n",
    "                          name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    tensor_for_label_input = tf.placeholder(tf.float32, \n",
    "                                            [None, n_classes],\n",
    "                                           name='y')\n",
    "    return tensor_for_label_input\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    keep_probs = tf.placeholder(tf.float32,\n",
    "                                name='keep_prob')\n",
    "    return keep_probs \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.random_normal([conv_ksize[0],\n",
    "                                           conv_ksize[1],\n",
    "                                           x_tensor.get_shape().as_list()[-1], \n",
    "                                           conv_num_outputs],\n",
    "                                         stddev=0.1))\n",
    "    \n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs, \n",
    "                                dtype=tf.float32))\n",
    "\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, \n",
    "                              weight, \n",
    "                              strides=[1, conv_strides[0], conv_strides[1], 1], \n",
    "                              padding='SAME')\n",
    "    \n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    \n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    conv_layer = tf.nn.max_pool(conv_layer, \n",
    "                                ksize=[1, pool_ksize[0], pool_ksize[1], 1], \n",
    "                                strides=[1, pool_strides[0], pool_strides[1], 1],\n",
    "                                padding='SAME')\n",
    "    \n",
    "    return conv_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    '''\n",
    "    https://www.tensorflow.org/api_docs/python/tf/contrib/layers/flatten\n",
    "    '''\n",
    "    super_flat = tf.contrib.layers.flatten(x_tensor)\n",
    "    return super_flat\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    width = x_tensor.get_shape().as_list()[1]\n",
    "    weight = tf.Variable(tf.truncated_normal(([width, num_outputs]), stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    output = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    relu = tf.nn.relu(output)\n",
    "    return relu\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    width = x_tensor.get_shape().as_list()[1]    \n",
    "    weight = tf.Variable(tf.truncated_normal([width, num_outputs], stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    return tf.nn.bias_add(tf.matmul(x_tensor,weight), bias)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_l_1 = conv2d_maxpool(x, 32, * [(5, 5), (1, 1), (2, 2), (2, 2)])\n",
    "    conv_l_1 = tf.nn.dropout(conv_l_1, keep_prob)\n",
    "    \n",
    "    conv_l_2 = conv2d_maxpool(conv_l_1, 64, * [(5, 5), (1, 1), (2, 2), (2, 2)])\n",
    "    conv_l_2 = tf.nn.dropout(conv_l_2, keep_prob)\n",
    "    \n",
    "    conv_l_3 = conv2d_maxpool(conv_l_2, 128, * [(5, 5), (1, 1), (2, 2), (2, 2)])\n",
    "    conv_l_3 = tf.nn.dropout(conv_l_3, keep_prob)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flatten_l_1 = flatten(conv_l_3)\n",
    "\n",
    "    # Apply 1, 2, or 3 Fully Connected Layers\n",
    "    fully_conn_l_1 = fully_conn(flatten_l_1, 256)\n",
    "    fully_conn_l_1 = tf.nn.dropout(fully_conn_l_1, keep_prob)\n",
    "    fully_conn_l_2 = fully_conn(flatten_l_1, 512)\n",
    "    fully_conn_l_2 = tf.nn.dropout(fully_conn_l_2, keep_prob)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    num_outputs = 10 # 10 labels_range!!!!!!!!! see above!!!!\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return output(fully_conn_l_2, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, \n",
    "                feed_dict={x:feature_batch,\n",
    "                           y:label_batch,\n",
    "                           keep_prob:keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    time_now = datetime.now()\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "    accuracy = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "    print(\"The loss is: {} The Acccuracy is: {} And now it's: {}\".format(loss, accuracy, time_now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\namazing set up!!!!\\nthe only drawback is that it takes forever to finish not using my graphic card\\n=> have to start using it asap!!! \\nI'll reduce the batch size from 256 to 128\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 30\n",
    "batch_size = 256\n",
    "keep_probability = 0.85\n",
    "'''\n",
    "amazing set up!!!!\n",
    "the only drawback is that it takes forever to finish not using my graphic card\n",
    "=> have to start using it asap!!! \n",
    "I'll reduce the batch size from 256 to 128\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  The loss is: 2.23124623298645 The cccuracy is: 0.24819999933242798\n",
      "Epoch  2, CIFAR-10 Batch 1:  The loss is: 1.9991865158081055 The cccuracy is: 0.35100001096725464\n",
      "Epoch  3, CIFAR-10 Batch 1:  The loss is: 1.7591097354888916 The cccuracy is: 0.4059999883174896\n",
      "Epoch  4, CIFAR-10 Batch 1:  The loss is: 1.5533329248428345 The cccuracy is: 0.42820000648498535\n",
      "Epoch  5, CIFAR-10 Batch 1:  The loss is: 1.3262665271759033 The cccuracy is: 0.46880000829696655\n",
      "Epoch  6, CIFAR-10 Batch 1:  The loss is: 1.2382872104644775 The cccuracy is: 0.46959999203681946\n",
      "Epoch  7, CIFAR-10 Batch 1:  The loss is: 1.1572189331054688 The cccuracy is: 0.4860000014305115\n",
      "Epoch  8, CIFAR-10 Batch 1:  The loss is: 0.9560310244560242 The cccuracy is: 0.5026000142097473\n",
      "Epoch  9, CIFAR-10 Batch 1:  The loss is: 0.8435114026069641 The cccuracy is: 0.5134000182151794\n",
      "Epoch 10, CIFAR-10 Batch 1:  The loss is: 0.726988673210144 The cccuracy is: 0.521399974822998\n",
      "Epoch 11, CIFAR-10 Batch 1:  The loss is: 0.6771091818809509 The cccuracy is: 0.5281999707221985\n",
      "Epoch 12, CIFAR-10 Batch 1:  The loss is: 0.5818007588386536 The cccuracy is: 0.5343999862670898\n",
      "Epoch 13, CIFAR-10 Batch 1:  The loss is: 0.4776698052883148 The cccuracy is: 0.5514000058174133\n",
      "Epoch 14, CIFAR-10 Batch 1:  The loss is: 0.4310358166694641 The cccuracy is: 0.5618000030517578\n",
      "Epoch 15, CIFAR-10 Batch 1:  The loss is: 0.3809383511543274 The cccuracy is: 0.5515999794006348\n",
      "Epoch 16, CIFAR-10 Batch 1:  The loss is: 0.36166077852249146 The cccuracy is: 0.5699999928474426\n",
      "Epoch 17, CIFAR-10 Batch 1:  The loss is: 0.26502832770347595 The cccuracy is: 0.5666000247001648\n",
      "Epoch 18, CIFAR-10 Batch 1:  The loss is: 0.22140637040138245 The cccuracy is: 0.574400007724762\n",
      "Epoch 19, CIFAR-10 Batch 1:  The loss is: 0.22104665637016296 The cccuracy is: 0.5673999786376953\n",
      "Epoch 20, CIFAR-10 Batch 1:  The loss is: 0.17097660899162292 The cccuracy is: 0.5774000287055969\n",
      "Epoch 21, CIFAR-10 Batch 1:  The loss is: 0.1404019296169281 The cccuracy is: 0.5938000082969666\n",
      "Epoch 22, CIFAR-10 Batch 1:  The loss is: 0.13204000890254974 The cccuracy is: 0.5879999995231628\n",
      "Epoch 23, CIFAR-10 Batch 1:  The loss is: 0.1226915568113327 The cccuracy is: 0.5907999873161316\n",
      "Epoch 24, CIFAR-10 Batch 1:  The loss is: 0.08206689357757568 The cccuracy is: 0.5910000205039978\n",
      "Epoch 25, CIFAR-10 Batch 1:  The loss is: 0.07674612104892731 The cccuracy is: 0.5961999893188477\n",
      "Epoch 26, CIFAR-10 Batch 1:  The loss is: 0.05918920040130615 The cccuracy is: 0.5992000102996826\n",
      "Epoch 27, CIFAR-10 Batch 1:  The loss is: 0.06821886450052261 The cccuracy is: 0.5759999752044678\n",
      "Epoch 28, CIFAR-10 Batch 1:  The loss is: 0.06665673106908798 The cccuracy is: 0.5830000042915344\n",
      "Epoch 29, CIFAR-10 Batch 1:  The loss is: 0.04398401454091072 The cccuracy is: 0.5917999744415283\n",
      "Epoch 30, CIFAR-10 Batch 1:  The loss is: 0.06149701029062271 The cccuracy is: 0.5752000212669373\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  The loss is: 2.2166061401367188 The Acccuracy is: 0.22120000422000885 And now it's: 2017-05-18 18:36:41.832699\n",
      "Epoch  1, CIFAR-10 Batch 2:  The loss is: 1.9548851251602173 The Acccuracy is: 0.32280001044273376 And now it's: 2017-05-18 18:37:21.056718\n",
      "Epoch  1, CIFAR-10 Batch 3:  The loss is: 1.6891510486602783 The Acccuracy is: 0.3734000027179718 And now it's: 2017-05-18 18:38:00.367610\n",
      "Epoch  1, CIFAR-10 Batch 4:  The loss is: 1.6362533569335938 The Acccuracy is: 0.3977999985218048 And now it's: 2017-05-18 18:38:39.836624\n",
      "Epoch  1, CIFAR-10 Batch 5:  The loss is: 1.6709972620010376 The Acccuracy is: 0.43299999833106995 And now it's: 2017-05-18 18:39:19.261704\n",
      "Epoch  2, CIFAR-10 Batch 1:  The loss is: 1.760791540145874 The Acccuracy is: 0.46239998936653137 And now it's: 2017-05-18 18:39:58.433122\n",
      "Epoch  2, CIFAR-10 Batch 2:  The loss is: 1.4918131828308105 The Acccuracy is: 0.4668000042438507 And now it's: 2017-05-18 18:40:37.572686\n",
      "Epoch  2, CIFAR-10 Batch 3:  The loss is: 1.2915489673614502 The Acccuracy is: 0.45879998803138733 And now it's: 2017-05-18 18:41:16.886191\n",
      "Epoch  2, CIFAR-10 Batch 4:  The loss is: 1.3951661586761475 The Acccuracy is: 0.48579999804496765 And now it's: 2017-05-18 18:41:56.262629\n",
      "Epoch  2, CIFAR-10 Batch 5:  The loss is: 1.450455665588379 The Acccuracy is: 0.5099999904632568 And now it's: 2017-05-18 18:42:35.695738\n",
      "Epoch  3, CIFAR-10 Batch 1:  The loss is: 1.4731390476226807 The Acccuracy is: 0.5252000093460083 And now it's: 2017-05-18 18:43:15.298268\n",
      "Epoch  3, CIFAR-10 Batch 2:  The loss is: 1.2056217193603516 The Acccuracy is: 0.5116000175476074 And now it's: 2017-05-18 18:43:53.207023\n",
      "Epoch  3, CIFAR-10 Batch 3:  The loss is: 1.0517175197601318 The Acccuracy is: 0.5117999911308289 And now it's: 2017-05-18 18:44:32.812123\n",
      "Epoch  3, CIFAR-10 Batch 4:  The loss is: 1.2153522968292236 The Acccuracy is: 0.520799994468689 And now it's: 2017-05-18 18:45:11.882345\n",
      "Epoch  3, CIFAR-10 Batch 5:  The loss is: 1.190470814704895 The Acccuracy is: 0.5509999990463257 And now it's: 2017-05-18 18:45:51.314966\n",
      "Epoch  4, CIFAR-10 Batch 1:  The loss is: 1.175204873085022 The Acccuracy is: 0.5645999908447266 And now it's: 2017-05-18 18:46:30.586813\n",
      "Epoch  4, CIFAR-10 Batch 2:  The loss is: 1.0389089584350586 The Acccuracy is: 0.5591999888420105 And now it's: 2017-05-18 18:47:09.581450\n",
      "Epoch  4, CIFAR-10 Batch 3:  The loss is: 0.8476625680923462 The Acccuracy is: 0.5619999766349792 And now it's: 2017-05-18 18:47:48.509024\n",
      "Epoch  4, CIFAR-10 Batch 4:  The loss is: 1.0508382320404053 The Acccuracy is: 0.5658000111579895 And now it's: 2017-05-18 18:48:27.744936\n",
      "Epoch  4, CIFAR-10 Batch 5:  The loss is: 1.008427381515503 The Acccuracy is: 0.5784000158309937 And now it's: 2017-05-18 18:49:07.062403\n",
      "Epoch  5, CIFAR-10 Batch 1:  The loss is: 0.9805795550346375 The Acccuracy is: 0.5942000150680542 And now it's: 2017-05-18 18:49:45.540728\n",
      "Epoch  5, CIFAR-10 Batch 2:  The loss is: 0.8324947357177734 The Acccuracy is: 0.5961999893188477 And now it's: 2017-05-18 18:50:24.871080\n",
      "Epoch  5, CIFAR-10 Batch 3:  The loss is: 0.6848350763320923 The Acccuracy is: 0.59579998254776 And now it's: 2017-05-18 18:51:04.740575\n",
      "Epoch  5, CIFAR-10 Batch 4:  The loss is: 0.8802616000175476 The Acccuracy is: 0.5824000239372253 And now it's: 2017-05-18 18:51:43.762897\n",
      "Epoch  5, CIFAR-10 Batch 5:  The loss is: 0.7900427579879761 The Acccuracy is: 0.6212000250816345 And now it's: 2017-05-18 18:52:23.093458\n",
      "Epoch  6, CIFAR-10 Batch 1:  The loss is: 0.8556509017944336 The Acccuracy is: 0.6187999844551086 And now it's: 2017-05-18 18:53:01.852933\n",
      "Epoch  6, CIFAR-10 Batch 2:  The loss is: 0.6821161508560181 The Acccuracy is: 0.5965999960899353 And now it's: 2017-05-18 18:53:41.061301\n",
      "Epoch  6, CIFAR-10 Batch 3:  The loss is: 0.5525850057601929 The Acccuracy is: 0.6263999938964844 And now it's: 2017-05-18 18:54:20.239021\n",
      "Epoch  6, CIFAR-10 Batch 4:  The loss is: 0.7300098538398743 The Acccuracy is: 0.6190000176429749 And now it's: 2017-05-18 18:54:59.857027\n",
      "Epoch  6, CIFAR-10 Batch 5:  The loss is: 0.5989022254943848 The Acccuracy is: 0.6380000114440918 And now it's: 2017-05-18 18:55:38.397419\n",
      "Epoch  7, CIFAR-10 Batch 1:  The loss is: 0.724806010723114 The Acccuracy is: 0.6456000208854675 And now it's: 2017-05-18 18:56:17.427027\n",
      "Epoch  7, CIFAR-10 Batch 2:  The loss is: 0.6187533736228943 The Acccuracy is: 0.6155999898910522 And now it's: 2017-05-18 18:56:57.122092\n",
      "Epoch  7, CIFAR-10 Batch 3:  The loss is: 0.4448487162590027 The Acccuracy is: 0.6313999891281128 And now it's: 2017-05-18 18:57:36.457360\n",
      "Epoch  7, CIFAR-10 Batch 4:  The loss is: 0.5682922005653381 The Acccuracy is: 0.6444000005722046 And now it's: 2017-05-18 18:58:15.732206\n",
      "Epoch  7, CIFAR-10 Batch 5:  The loss is: 0.5395941734313965 The Acccuracy is: 0.6462000012397766 And now it's: 2017-05-18 18:58:53.968738\n",
      "Epoch  8, CIFAR-10 Batch 1:  The loss is: 0.6104665994644165 The Acccuracy is: 0.6456000208854675 And now it's: 2017-05-18 18:59:33.418301\n",
      "Epoch  8, CIFAR-10 Batch 2:  The loss is: 0.4883193075656891 The Acccuracy is: 0.6172000169754028 And now it's: 2017-05-18 19:00:13.423286\n",
      "Epoch  8, CIFAR-10 Batch 3:  The loss is: 0.4160861074924469 The Acccuracy is: 0.6452000141143799 And now it's: 2017-05-18 19:00:53.190140\n",
      "Epoch  8, CIFAR-10 Batch 4:  The loss is: 0.4980156421661377 The Acccuracy is: 0.6565999984741211 And now it's: 2017-05-18 19:01:32.507646\n",
      "Epoch  8, CIFAR-10 Batch 5:  The loss is: 0.4374437928199768 The Acccuracy is: 0.6636000275611877 And now it's: 2017-05-18 19:02:11.217985\n",
      "Epoch  9, CIFAR-10 Batch 1:  The loss is: 0.5060219764709473 The Acccuracy is: 0.6715999841690063 And now it's: 2017-05-18 19:02:50.159853\n",
      "Epoch  9, CIFAR-10 Batch 2:  The loss is: 0.3980775475502014 The Acccuracy is: 0.6448000073432922 And now it's: 2017-05-18 19:03:29.471783\n",
      "Epoch  9, CIFAR-10 Batch 3:  The loss is: 0.34210437536239624 The Acccuracy is: 0.6679999828338623 And now it's: 2017-05-18 19:04:07.796493\n",
      "Epoch  9, CIFAR-10 Batch 4:  The loss is: 0.397979199886322 The Acccuracy is: 0.6733999848365784 And now it's: 2017-05-18 19:04:46.982681\n",
      "Epoch  9, CIFAR-10 Batch 5:  The loss is: 0.3841753900051117 The Acccuracy is: 0.670799970626831 And now it's: 2017-05-18 19:05:26.208003\n",
      "Epoch 10, CIFAR-10 Batch 1:  The loss is: 0.39908403158187866 The Acccuracy is: 0.6687999963760376 And now it's: 2017-05-18 19:06:05.771469\n",
      "Epoch 10, CIFAR-10 Batch 2:  The loss is: 0.3337436318397522 The Acccuracy is: 0.6705999970436096 And now it's: 2017-05-18 19:06:44.494279\n",
      "Epoch 10, CIFAR-10 Batch 3:  The loss is: 0.3190975487232208 The Acccuracy is: 0.6697999835014343 And now it's: 2017-05-18 19:07:24.199720\n",
      "Epoch 10, CIFAR-10 Batch 4:  The loss is: 0.3054308295249939 The Acccuracy is: 0.675599992275238 And now it's: 2017-05-18 19:08:03.592918\n",
      "Epoch 10, CIFAR-10 Batch 5:  The loss is: 0.3023415803909302 The Acccuracy is: 0.6872000098228455 And now it's: 2017-05-18 19:08:41.809144\n",
      "Epoch 11, CIFAR-10 Batch 1:  The loss is: 0.3380952477455139 The Acccuracy is: 0.6827999949455261 And now it's: 2017-05-18 19:09:21.024979\n",
      "Epoch 11, CIFAR-10 Batch 2:  The loss is: 0.28627699613571167 The Acccuracy is: 0.6800000071525574 And now it's: 2017-05-18 19:10:00.269487\n",
      "Epoch 11, CIFAR-10 Batch 3:  The loss is: 0.23902420699596405 The Acccuracy is: 0.6940000057220459 And now it's: 2017-05-18 19:10:39.700678\n",
      "Epoch 11, CIFAR-10 Batch 4:  The loss is: 0.262265682220459 The Acccuracy is: 0.6923999786376953 And now it's: 2017-05-18 19:11:18.844196\n",
      "Epoch 11, CIFAR-10 Batch 5:  The loss is: 0.20875930786132812 The Acccuracy is: 0.6898000240325928 And now it's: 2017-05-18 19:11:58.039233\n",
      "Epoch 12, CIFAR-10 Batch 1:  The loss is: 0.2792540192604065 The Acccuracy is: 0.6823999881744385 And now it's: 2017-05-18 19:12:37.369888\n",
      "Epoch 12, CIFAR-10 Batch 2:  The loss is: 0.20480385422706604 The Acccuracy is: 0.6827999949455261 And now it's: 2017-05-18 19:13:16.452799\n",
      "Epoch 12, CIFAR-10 Batch 3:  The loss is: 0.2168152779340744 The Acccuracy is: 0.6944000124931335 And now it's: 2017-05-18 19:13:55.594082\n",
      "Epoch 12, CIFAR-10 Batch 4:  The loss is: 0.2199530154466629 The Acccuracy is: 0.7017999887466431 And now it's: 2017-05-18 19:14:34.584896\n",
      "Epoch 12, CIFAR-10 Batch 5:  The loss is: 0.18143363296985626 The Acccuracy is: 0.6980000138282776 And now it's: 2017-05-18 19:15:13.796285\n",
      "Epoch 13, CIFAR-10 Batch 1:  The loss is: 0.2573755979537964 The Acccuracy is: 0.6953999996185303 And now it's: 2017-05-18 19:15:52.475277\n",
      "Epoch 13, CIFAR-10 Batch 2:  The loss is: 0.1831977367401123 The Acccuracy is: 0.6959999799728394 And now it's: 2017-05-18 19:16:31.867505\n",
      "Epoch 13, CIFAR-10 Batch 3:  The loss is: 0.19144542515277863 The Acccuracy is: 0.7013999819755554 And now it's: 2017-05-18 19:17:10.721433\n",
      "Epoch 13, CIFAR-10 Batch 4:  The loss is: 0.17818255722522736 The Acccuracy is: 0.7107999920845032 And now it's: 2017-05-18 19:17:48.703754\n",
      "Epoch 13, CIFAR-10 Batch 5:  The loss is: 0.17044015228748322 The Acccuracy is: 0.6970000267028809 And now it's: 2017-05-18 19:18:27.847111\n",
      "Epoch 14, CIFAR-10 Batch 1:  The loss is: 0.16302385926246643 The Acccuracy is: 0.7093999981880188 And now it's: 2017-05-18 19:19:07.245490\n",
      "Epoch 14, CIFAR-10 Batch 2:  The loss is: 0.12207838147878647 The Acccuracy is: 0.7052000164985657 And now it's: 2017-05-18 19:19:46.741668\n",
      "Epoch 14, CIFAR-10 Batch 3:  The loss is: 0.15146639943122864 The Acccuracy is: 0.7006000280380249 And now it's: 2017-05-18 19:20:25.910217\n",
      "Epoch 14, CIFAR-10 Batch 4:  The loss is: 0.14290300011634827 The Acccuracy is: 0.7131999731063843 And now it's: 2017-05-18 19:21:05.181234\n",
      "Epoch 14, CIFAR-10 Batch 5:  The loss is: 0.12188659608364105 The Acccuracy is: 0.7038000226020813 And now it's: 2017-05-18 19:21:44.913124\n",
      "Epoch 15, CIFAR-10 Batch 1:  The loss is: 0.13946621119976044 The Acccuracy is: 0.7113999724388123 And now it's: 2017-05-18 19:22:24.223733\n",
      "Epoch 15, CIFAR-10 Batch 2:  The loss is: 0.12414983659982681 The Acccuracy is: 0.7152000069618225 And now it's: 2017-05-18 19:23:03.667018\n",
      "Epoch 15, CIFAR-10 Batch 3:  The loss is: 0.08633525669574738 The Acccuracy is: 0.7215999960899353 And now it's: 2017-05-18 19:23:42.681132\n",
      "Epoch 15, CIFAR-10 Batch 4:  The loss is: 0.10131502151489258 The Acccuracy is: 0.7233999967575073 And now it's: 2017-05-18 19:24:21.960787\n",
      "Epoch 15, CIFAR-10 Batch 5:  The loss is: 0.1062735915184021 The Acccuracy is: 0.7113999724388123 And now it's: 2017-05-18 19:25:01.171363\n",
      "Epoch 16, CIFAR-10 Batch 1:  The loss is: 0.1381099969148636 The Acccuracy is: 0.7265999913215637 And now it's: 2017-05-18 19:25:39.648182\n",
      "Epoch 16, CIFAR-10 Batch 2:  The loss is: 0.09857745468616486 The Acccuracy is: 0.7156000137329102 And now it's: 2017-05-18 19:26:18.829219\n",
      "Epoch 16, CIFAR-10 Batch 3:  The loss is: 0.0970306470990181 The Acccuracy is: 0.722000002861023 And now it's: 2017-05-18 19:26:58.353312\n",
      "Epoch 16, CIFAR-10 Batch 4:  The loss is: 0.0834832638502121 The Acccuracy is: 0.7239999771118164 And now it's: 2017-05-18 19:27:37.824654\n",
      "Epoch 16, CIFAR-10 Batch 5:  The loss is: 0.07662936300039291 The Acccuracy is: 0.7161999940872192 And now it's: 2017-05-18 19:28:16.990365\n",
      "Epoch 17, CIFAR-10 Batch 1:  The loss is: 0.13066308200359344 The Acccuracy is: 0.7264000177383423 And now it's: 2017-05-18 19:28:56.401146\n",
      "Epoch 17, CIFAR-10 Batch 2:  The loss is: 0.07927794754505157 The Acccuracy is: 0.72079998254776 And now it's: 2017-05-18 19:29:35.403149\n",
      "Epoch 17, CIFAR-10 Batch 3:  The loss is: 0.07781282812356949 The Acccuracy is: 0.718999981880188 And now it's: 2017-05-18 19:30:14.822666\n",
      "Epoch 17, CIFAR-10 Batch 4:  The loss is: 0.07974936068058014 The Acccuracy is: 0.7271999716758728 And now it's: 2017-05-18 19:30:54.265106\n",
      "Epoch 17, CIFAR-10 Batch 5:  The loss is: 0.06229104846715927 The Acccuracy is: 0.7228000164031982 And now it's: 2017-05-18 19:31:34.094688\n",
      "Epoch 18, CIFAR-10 Batch 1:  The loss is: 0.08686604350805283 The Acccuracy is: 0.7264000177383423 And now it's: 2017-05-18 19:32:13.424267\n",
      "Epoch 18, CIFAR-10 Batch 2:  The loss is: 0.06953708082437515 The Acccuracy is: 0.7192000150680542 And now it's: 2017-05-18 19:32:52.675202\n",
      "Epoch 18, CIFAR-10 Batch 3:  The loss is: 0.04695575684309006 The Acccuracy is: 0.7275999784469604 And now it's: 2017-05-18 19:33:30.761234\n",
      "Epoch 18, CIFAR-10 Batch 4:  The loss is: 0.0707419216632843 The Acccuracy is: 0.7342000007629395 And now it's: 2017-05-18 19:34:09.755852\n",
      "Epoch 18, CIFAR-10 Batch 5:  The loss is: 0.06142225116491318 The Acccuracy is: 0.7211999893188477 And now it's: 2017-05-18 19:34:48.866452\n",
      "Epoch 19, CIFAR-10 Batch 1:  The loss is: 0.07027485221624374 The Acccuracy is: 0.7414000034332275 And now it's: 2017-05-18 19:35:28.188292\n",
      "Epoch 19, CIFAR-10 Batch 2:  The loss is: 0.06576452404260635 The Acccuracy is: 0.7235999703407288 And now it's: 2017-05-18 19:36:07.437053\n",
      "Epoch 19, CIFAR-10 Batch 3:  The loss is: 0.04121984913945198 The Acccuracy is: 0.7342000007629395 And now it's: 2017-05-18 19:36:46.242963\n",
      "Epoch 19, CIFAR-10 Batch 4:  The loss is: 0.05181128904223442 The Acccuracy is: 0.7386000156402588 And now it's: 2017-05-18 19:37:24.953236\n",
      "Epoch 19, CIFAR-10 Batch 5:  The loss is: 0.04184703528881073 The Acccuracy is: 0.7325999736785889 And now it's: 2017-05-18 19:38:04.017992\n",
      "Epoch 20, CIFAR-10 Batch 1:  The loss is: 0.08388370275497437 The Acccuracy is: 0.7343999743461609 And now it's: 2017-05-18 19:38:43.360285\n",
      "Epoch 20, CIFAR-10 Batch 2:  The loss is: 0.05569760873913765 The Acccuracy is: 0.7265999913215637 And now it's: 2017-05-18 19:39:22.152408\n",
      "Epoch 20, CIFAR-10 Batch 3:  The loss is: 0.039998941123485565 The Acccuracy is: 0.7260000109672546 And now it's: 2017-05-18 19:40:01.630739\n",
      "Epoch 20, CIFAR-10 Batch 4:  The loss is: 0.06277463585138321 The Acccuracy is: 0.7364000082015991 And now it's: 2017-05-18 19:40:40.177329\n",
      "Epoch 20, CIFAR-10 Batch 5:  The loss is: 0.0340706966817379 The Acccuracy is: 0.723800003528595 And now it's: 2017-05-18 19:41:19.717247\n",
      "Epoch 21, CIFAR-10 Batch 1:  The loss is: 0.04800865426659584 The Acccuracy is: 0.7314000129699707 And now it's: 2017-05-18 19:41:59.721188\n",
      "Epoch 21, CIFAR-10 Batch 2:  The loss is: 0.056893300265073776 The Acccuracy is: 0.7239999771118164 And now it's: 2017-05-18 19:42:39.223147\n",
      "Epoch 21, CIFAR-10 Batch 3:  The loss is: 0.05326563119888306 The Acccuracy is: 0.7107999920845032 And now it's: 2017-05-18 19:43:17.900287\n",
      "Epoch 21, CIFAR-10 Batch 4:  The loss is: 0.042425550520420074 The Acccuracy is: 0.7336000204086304 And now it's: 2017-05-18 19:43:57.459124\n",
      "Epoch 21, CIFAR-10 Batch 5:  The loss is: 0.03418046981096268 The Acccuracy is: 0.732200026512146 And now it's: 2017-05-18 19:44:36.940087\n",
      "Epoch 22, CIFAR-10 Batch 1:  The loss is: 0.05111144855618477 The Acccuracy is: 0.7332000136375427 And now it's: 2017-05-18 19:45:15.734275\n",
      "Epoch 22, CIFAR-10 Batch 2:  The loss is: 0.03759375959634781 The Acccuracy is: 0.734000027179718 And now it's: 2017-05-18 19:45:54.700210\n",
      "Epoch 22, CIFAR-10 Batch 3:  The loss is: 0.025467876344919205 The Acccuracy is: 0.72079998254776 And now it's: 2017-05-18 19:46:34.153365\n",
      "Epoch 22, CIFAR-10 Batch 4:  The loss is: 0.04065617173910141 The Acccuracy is: 0.7455999851226807 And now it's: 2017-05-18 19:47:13.417482\n",
      "Epoch 22, CIFAR-10 Batch 5:  The loss is: 0.021728184074163437 The Acccuracy is: 0.7265999913215637 And now it's: 2017-05-18 19:47:53.097787\n",
      "Epoch 23, CIFAR-10 Batch 1:  The loss is: 0.036050185561180115 The Acccuracy is: 0.7307999730110168 And now it's: 2017-05-18 19:48:32.783020\n",
      "Epoch 23, CIFAR-10 Batch 2:  The loss is: 0.03024187684059143 The Acccuracy is: 0.7450000047683716 And now it's: 2017-05-18 19:49:12.315241\n",
      "Epoch 23, CIFAR-10 Batch 3:  The loss is: 0.041467051953077316 The Acccuracy is: 0.699400007724762 And now it's: 2017-05-18 19:49:51.764890\n",
      "Epoch 23, CIFAR-10 Batch 4:  The loss is: 0.038313884288072586 The Acccuracy is: 0.7418000102043152 And now it's: 2017-05-18 19:50:31.601910\n",
      "Epoch 23, CIFAR-10 Batch 5:  The loss is: 0.01706879399716854 The Acccuracy is: 0.7437999844551086 And now it's: 2017-05-18 19:51:10.938799\n",
      "Epoch 24, CIFAR-10 Batch 1:  The loss is: 0.03956606984138489 The Acccuracy is: 0.7458000183105469 And now it's: 2017-05-18 19:51:50.244099\n",
      "Epoch 24, CIFAR-10 Batch 2:  The loss is: 0.03712986037135124 The Acccuracy is: 0.7383999824523926 And now it's: 2017-05-18 19:52:33.279706\n",
      "Epoch 24, CIFAR-10 Batch 3:  The loss is: 0.017535334452986717 The Acccuracy is: 0.7325999736785889 And now it's: 2017-05-18 19:53:12.514455\n",
      "Epoch 24, CIFAR-10 Batch 4:  The loss is: 0.02726249024271965 The Acccuracy is: 0.746399998664856 And now it's: 2017-05-18 19:53:51.401901\n",
      "Epoch 24, CIFAR-10 Batch 5:  The loss is: 0.014742881059646606 The Acccuracy is: 0.745199978351593 And now it's: 2017-05-18 19:54:30.671161\n",
      "Epoch 25, CIFAR-10 Batch 1:  The loss is: 0.026117954403162003 The Acccuracy is: 0.7376000285148621 And now it's: 2017-05-18 19:55:09.192498\n",
      "Epoch 25, CIFAR-10 Batch 2:  The loss is: 0.018369775265455246 The Acccuracy is: 0.7383999824523926 And now it's: 2017-05-18 19:55:47.447493\n",
      "Epoch 25, CIFAR-10 Batch 3:  The loss is: 0.011740265414118767 The Acccuracy is: 0.7391999959945679 And now it's: 2017-05-18 19:56:26.840334\n",
      "Epoch 25, CIFAR-10 Batch 4:  The loss is: 0.02143172174692154 The Acccuracy is: 0.7491999864578247 And now it's: 2017-05-18 19:57:05.922402\n",
      "Epoch 25, CIFAR-10 Batch 5:  The loss is: 0.012399534694850445 The Acccuracy is: 0.7419999837875366 And now it's: 2017-05-18 19:57:45.209191\n",
      "Epoch 26, CIFAR-10 Batch 1:  The loss is: 0.02787427231669426 The Acccuracy is: 0.7318000197410583 And now it's: 2017-05-18 19:58:24.398809\n",
      "Epoch 26, CIFAR-10 Batch 2:  The loss is: 0.012505283579230309 The Acccuracy is: 0.7462000250816345 And now it's: 2017-05-18 19:59:03.689009\n",
      "Epoch 26, CIFAR-10 Batch 3:  The loss is: 0.01152697391808033 The Acccuracy is: 0.7268000245094299 And now it's: 2017-05-18 19:59:42.545669\n",
      "Epoch 26, CIFAR-10 Batch 4:  The loss is: 0.024160370230674744 The Acccuracy is: 0.7516000270843506 And now it's: 2017-05-18 20:00:21.811941\n",
      "Epoch 26, CIFAR-10 Batch 5:  The loss is: 0.010742850601673126 The Acccuracy is: 0.7468000054359436 And now it's: 2017-05-18 20:01:01.273550\n",
      "Epoch 27, CIFAR-10 Batch 1:  The loss is: 0.024561192840337753 The Acccuracy is: 0.7386000156402588 And now it's: 2017-05-18 20:01:39.739536\n",
      "Epoch 27, CIFAR-10 Batch 2:  The loss is: 0.01189045887440443 The Acccuracy is: 0.7494000196456909 And now it's: 2017-05-18 20:02:18.808815\n",
      "Epoch 27, CIFAR-10 Batch 3:  The loss is: 0.0072470130398869514 The Acccuracy is: 0.741599977016449 And now it's: 2017-05-18 20:02:57.895766\n",
      "Epoch 27, CIFAR-10 Batch 4:  The loss is: 0.015022626146674156 The Acccuracy is: 0.7445999979972839 And now it's: 2017-05-18 20:03:37.278295\n",
      "Epoch 27, CIFAR-10 Batch 5:  The loss is: 0.010444623418152332 The Acccuracy is: 0.745199978351593 And now it's: 2017-05-18 20:04:16.472432\n",
      "Epoch 28, CIFAR-10 Batch 1:  The loss is: 0.020895356312394142 The Acccuracy is: 0.743399977684021 And now it's: 2017-05-18 20:04:55.286140\n",
      "Epoch 28, CIFAR-10 Batch 2:  The loss is: 0.005702379159629345 The Acccuracy is: 0.7437999844551086 And now it's: 2017-05-18 20:05:34.560495\n",
      "Epoch 28, CIFAR-10 Batch 3:  The loss is: 0.007240822073072195 The Acccuracy is: 0.7400000095367432 And now it's: 2017-05-18 20:06:13.153557\n",
      "Epoch 28, CIFAR-10 Batch 4:  The loss is: 0.01105549931526184 The Acccuracy is: 0.746999979019165 And now it's: 2017-05-18 20:06:52.775601\n",
      "Epoch 28, CIFAR-10 Batch 5:  The loss is: 0.007127971854060888 The Acccuracy is: 0.7419999837875366 And now it's: 2017-05-18 20:07:31.939948\n",
      "Epoch 29, CIFAR-10 Batch 1:  The loss is: 0.01964733377099037 The Acccuracy is: 0.7552000284194946 And now it's: 2017-05-18 20:08:10.924341\n",
      "Epoch 29, CIFAR-10 Batch 2:  The loss is: 0.005873166956007481 The Acccuracy is: 0.7426000237464905 And now it's: 2017-05-18 20:08:49.270155\n",
      "Epoch 29, CIFAR-10 Batch 3:  The loss is: 0.006877063307911158 The Acccuracy is: 0.7512000203132629 And now it's: 2017-05-18 20:09:28.500081\n",
      "Epoch 29, CIFAR-10 Batch 4:  The loss is: 0.010553976520895958 The Acccuracy is: 0.7405999898910522 And now it's: 2017-05-18 20:10:07.598937\n",
      "Epoch 29, CIFAR-10 Batch 5:  The loss is: 0.011691747233271599 The Acccuracy is: 0.748199999332428 And now it's: 2017-05-18 20:10:46.894344\n",
      "Epoch 30, CIFAR-10 Batch 1:  The loss is: 0.007893146947026253 The Acccuracy is: 0.756600022315979 And now it's: 2017-05-18 20:11:25.208089\n",
      "Epoch 30, CIFAR-10 Batch 2:  The loss is: 0.012974184937775135 The Acccuracy is: 0.7342000007629395 And now it's: 2017-05-18 20:12:04.587452\n",
      "Epoch 30, CIFAR-10 Batch 3:  The loss is: 0.00628411490470171 The Acccuracy is: 0.7447999715805054 And now it's: 2017-05-18 20:12:43.509060\n",
      "Epoch 30, CIFAR-10 Batch 4:  The loss is: 0.00740944454446435 The Acccuracy is: 0.7490000128746033 And now it's: 2017-05-18 20:13:22.741965\n",
      "Epoch 30, CIFAR-10 Batch 5:  The loss is: 0.0102588701993227 The Acccuracy is: 0.727400004863739 And now it's: 2017-05-18 20:14:01.588987\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.71455078125\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiIpEmxyIiIiIikSbHIiIiIiLR/wdNpFiUnk+gvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d28cf28>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:image_classification]",
   "language": "python",
   "name": "conda-env-image_classification-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
